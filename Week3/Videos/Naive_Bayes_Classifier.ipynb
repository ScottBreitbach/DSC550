{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning 3/5: Naive Bayes Classifier\n",
    "https://www.youtube.com/watch?v=j3IGd5CjsVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import re\n",
    "import sys\n",
    "from collections import Counter, defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    '''Break up text into words'''\n",
    "    return re.findall('[a-z0-9]+', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_title_body(title, body):\n",
    "    '''Break up text into title and body that do not overlap'''\n",
    "    return [\"title:\" + t for t in tokenize(title)] + [\"body:\" + b for b in tokenize(body)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Could also tokenize based on bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_training_file(filename):\n",
    "    priors = Counter()\n",
    "    likelihood = defaultdict(Counter)\n",
    "    \n",
    "    with open(filename) as f:\n",
    "        for line in f:\n",
    "            parts = line.split('\\t')\n",
    "            priors[parts[1]] += 1\n",
    "#             for word in tokenize(parts[2]):\n",
    "#             for word in tokenize(parts[2] + \" \" + parts[3]):   # Add title, body   \n",
    "            for word in tokenize_title_body(parts[2], parts[3]):   # Split title, body                     \n",
    "                likelihood[parts[1]][word]+= 1\n",
    "    \n",
    "    return (priors, likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def classify(line, priors, likelihood):\n",
    "#     '''Return a random category'''\n",
    "#     categories = priors.keys()\n",
    "#     return categories[int(random.random() * len(categories))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_random(line, priors, likelihood):\n",
    "    '''Return a random category'''\n",
    "    categories = priors.keys()\n",
    "    return categories[int(random.random() * len(categories))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_max_prior(line, priors, likelihood):\n",
    "    '''Return biggest category'''\n",
    "    return max(priors, key=lambda x: priors[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_bayesian(line, priors, likelihood):\n",
    "    '''Return the class that maximizes the posterior'''\n",
    "    max_class = (-1E6, '')\n",
    "    for c in priors.keys():\n",
    "#         p = priors[c]\n",
    "        p = math.log(priors[c])\n",
    "        n = float(sum(likelihood[c].values()))\n",
    "#         for word in tokenize(line[2]):\n",
    "#         for word in tokenize(line[2] + \" \" + line[3]):  # Add title, body  \n",
    "        for word in tokenize_title_body(line[2], line[3]):  # Split title, body                    \n",
    "#             p = p * likelihood[c][word] / n\n",
    "#             p = p * max(1E-6, likelihood[c][word] / n)  # Zero fix (can try 1E-2, 6, 9, etc; 9 eventually gave us more 0s, fix with logs\n",
    "#             p = p + math.log(max(1E-9, likelihood[c][word] / n))\n",
    "            if word.startswith('title'):\n",
    "                p = p + math.log(max(1E-9, 2 * likelihood[c][word] / n))\n",
    "            else:\n",
    "                p = p + math.log(max(1E-9, likelihood[c][word] / n))\n",
    "            \n",
    "        if p > max_class[0]:\n",
    "            max_class = (p, c)\n",
    "    \n",
    "#     print(max_class)\n",
    "    return max_class[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_testing_file(filename):\n",
    "    return [line.strip().split('\\t') for line in open(filename).readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    training_file = sys.argv[1]\n",
    "    testing_file = sys.argv[2]\n",
    "    \n",
    "    (priors, likelihood) = read_training_file(training_file)\n",
    "#     print(priors)\n",
    "#     print(likelihood)\n",
    "    lines = read_testing_file(testing_file)\n",
    "    for line in lines:\n",
    "#         if classify(line, priors, likelihood) == line[1]:\n",
    "#         if classify_max_prior(line, priors, likelihood) == line[1]:\n",
    "        if classify_bayesian(line, priors, likelihood) == line[1]:     \n",
    "            num_correct += 1\n",
    "            \n",
    "    print(\"Classified %d correctly out of %d for an accuracy of %f\"%(num_correct, len(lines), float(num_correct)/len(lines)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
