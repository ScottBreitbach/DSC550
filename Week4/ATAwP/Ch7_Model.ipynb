{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Can we talk about something else?\n",
      "Can we talk about something else?\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import nltk\n",
    "\n",
    "from math import log\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "from nltk.util import ngrams\n",
    "from nltk.probability import ProbDistI, FreqDist, ConditionalFreqDist\n",
    "\n",
    "from reader import PickledCorpusReader\n",
    "\n",
    "\n",
    "def count_ngrams(n, vocabulary, texts):\n",
    "    counter = NgramCounter(n, vocabulary)\n",
    "    counter.train_counts(texts)\n",
    "    return counter\n",
    "\n",
    "\n",
    "class NgramCounter(object):\n",
    "    \"\"\"\n",
    "    The NgramCounter class counts ngrams given a vocabulary and ngram size.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n, vocabulary, unknown=\"<UNK>\"):\n",
    "        \"\"\"\n",
    "        n is the size of the ngram\n",
    "        \"\"\"\n",
    "        if n < 1:\n",
    "            raise ValueError(\"ngram size must be greater than or equal to 1\")\n",
    "\n",
    "        self.n = n\n",
    "        self.unknown = unknown\n",
    "        self.padding = {\n",
    "            \"pad_left\": True,\n",
    "            \"pad_right\": True,\n",
    "            \"left_pad_symbol\": \"<s>\",\n",
    "            \"right_pad_symbol\": \"</s>\"\n",
    "        }\n",
    "\n",
    "        self.vocabulary = vocabulary\n",
    "        self.allgrams = defaultdict(ConditionalFreqDist)\n",
    "        self.ngrams = FreqDist()\n",
    "        self.unigrams = FreqDist()\n",
    "\n",
    "    def train_counts(self, training_text):\n",
    "        for sent in training_text:\n",
    "            checked_sent = (self.check_against_vocab(word) for word in sent)\n",
    "            sent_start = True\n",
    "            for ngram in self.to_ngrams(checked_sent):\n",
    "                self.ngrams[ngram] += 1\n",
    "                context, word = tuple(ngram[:-1]), ngram[-1]\n",
    "                if sent_start:\n",
    "                    for context_word in context:\n",
    "                        self.unigrams[context_word] += 1\n",
    "                    sent_start = False\n",
    "\n",
    "                for window, ngram_order in enumerate(range(self.n, 1, -1)):\n",
    "                    context = context[window:]\n",
    "                    self.allgrams[ngram_order][context][word] += 1\n",
    "                self.unigrams[word] += 1\n",
    "\n",
    "    def check_against_vocab(self, word):\n",
    "        if word in self.vocabulary:\n",
    "            return word\n",
    "        return self.unknown\n",
    "\n",
    "    def to_ngrams(self, sequence):\n",
    "        \"\"\"\n",
    "        Wrapper for NLTK ngrams method\n",
    "        \"\"\"\n",
    "        return ngrams(sequence, self.n, **self.padding)\n",
    "\n",
    "\n",
    "class BaseNgramModel(object):\n",
    "    \"\"\"\n",
    "    The BaseNgramModel creates an n-gram language model.\n",
    "    This base model is equivalent to a Maximum Likelihood Estimation.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ngram_counter):\n",
    "        \"\"\"\n",
    "        BaseNgramModel is initialized with an NgramCounter.\n",
    "        \"\"\"\n",
    "        self.n = ngram_counter.n\n",
    "        self.ngram_counter = ngram_counter\n",
    "        self.ngrams = ngram_counter.ngrams\n",
    "        self._check_against_vocab = self.ngram_counter.check_against_vocab\n",
    "\n",
    "    def check_context(self, context):\n",
    "        \"\"\"\n",
    "        Ensures that the context is not longer than or equal to the model's\n",
    "        n-gram order.\n",
    "\n",
    "        Returns the context as a tuple.\n",
    "        \"\"\"\n",
    "        if len(context) >= self.n:\n",
    "            raise ValueError(\"Context too long for this n-gram\")\n",
    "\n",
    "        return tuple(context)\n",
    "\n",
    "    def score(self, word, context):\n",
    "        \"\"\"\n",
    "        For a given string representation of a word, and a string word context,\n",
    "        returns the maximum likelihood score that the word will follow the\n",
    "        context.\n",
    "        \"\"\"\n",
    "        context = self.check_context(context)\n",
    "\n",
    "        return self.ngrams[context].freq(word)\n",
    "\n",
    "    def logscore(self, word, context):\n",
    "        \"\"\"\n",
    "        For a given string representation of a word, and a word context,\n",
    "        computes the log probability of this word in this context.\n",
    "        \"\"\"\n",
    "        score = self.score(word, context)\n",
    "        if score == 0.0:\n",
    "            return float(\"-inf\")\n",
    "\n",
    "        return log(score, 2)\n",
    "\n",
    "    def entropy(self, text):\n",
    "        \"\"\"\n",
    "        Calculate the approximate cross-entropy of the n-gram model for a\n",
    "        given text represented as a list of comma-separated strings.\n",
    "        This is the average log probability of each word in the text.\n",
    "        \"\"\"\n",
    "        normed_text = (self._check_against_vocab(word) for word in text)\n",
    "        entropy = 0.0\n",
    "        processed_ngrams = 0\n",
    "        for ngram in self.ngram_counter.to_ngrams(normed_text):\n",
    "            context, word = tuple(ngram[:-1]), ngram[-1]\n",
    "            entropy += self.logscore(word, context)\n",
    "            processed_ngrams += 1\n",
    "        return - (entropy / processed_ngrams)\n",
    "\n",
    "    def perplexity(self, text):\n",
    "        \"\"\"\n",
    "        Given list of comma-separated strings, calculates the perplexity\n",
    "        of the text.\n",
    "        \"\"\"\n",
    "        return pow(2.0, self.entropy(text))\n",
    "\n",
    "\n",
    "class AddKNgramModel(BaseNgramModel):\n",
    "    \"\"\"\n",
    "    Provides Add-k-smoothed scores.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, k, *args):\n",
    "        \"\"\"\n",
    "        Expects an input value, k, a number by which\n",
    "        to increment word counts during scoring.\n",
    "        \"\"\"\n",
    "        super(AddKNgramModel, self).__init__(*args)\n",
    "\n",
    "        self.k = k\n",
    "        self.k_norm = len(self.ngram_counter.vocabulary) * k\n",
    "\n",
    "    def score(self, word, context):\n",
    "        \"\"\"\n",
    "        With Add-k-smoothing, the score is normalized with\n",
    "        a k value.\n",
    "        \"\"\"\n",
    "        context = self.check_context(context)\n",
    "        context_freqdist = self.ngrams[context]\n",
    "        word_count = context_freqdist[word]\n",
    "        context_count = context_freqdist.N()\n",
    "        return (word_count + self.k) / \\\n",
    "               (context_count + self.k_norm)\n",
    "\n",
    "\n",
    "class LaplaceNgramModel(AddKNgramModel):\n",
    "    \"\"\"\n",
    "    Implements Laplace (add one) smoothing.\n",
    "    Laplace smoothing is the base case of Add-k smoothing,\n",
    "    with k set to 1.\n",
    "    \"\"\"\n",
    "    def __init__(self, *args):\n",
    "        super(LaplaceNgramModel, self).__init__(1, *args)\n",
    "\n",
    "\n",
    "class KneserNeyModel(BaseNgramModel):\n",
    "    \"\"\"\n",
    "    Implements Kneser-Ney smoothing\n",
    "    \"\"\"\n",
    "    def __init__(self, *args):\n",
    "        super(KneserNeyModel, self).__init__(*args)\n",
    "        self.model = nltk.KneserNeyProbDist(self.ngrams)\n",
    "\n",
    "    def score(self, word, context):\n",
    "        \"\"\"\n",
    "        Use KneserNeyProbDist from NLTK to get score\n",
    "        \"\"\"\n",
    "        trigram = tuple((context[0], context[1], word))\n",
    "        return self.model.prob(trigram)\n",
    "\n",
    "    def samples(self):\n",
    "        return self.model.samples()\n",
    "\n",
    "    def prob(self, sample):\n",
    "        return self.model.prob(sample)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    corpus = PickledCorpusReader('../ATAwP/corpus')\n",
    "    tokens = [''.join(word) for word in corpus.words()]\n",
    "    vocab = Counter(tokens)\n",
    "    sents = list([word[0] for word in sent] for sent in corpus.sents())\n",
    "\n",
    "    counter = count_ngrams(3, vocab, sents)\n",
    "    knm = KneserNeyModel(counter)\n",
    "\n",
    "\n",
    "    def complete(input_text):\n",
    "        tokenized = nltk.word_tokenize(input_text)\n",
    "        if len(tokenized) < 2:\n",
    "            response = \"Say more.\"\n",
    "        else:\n",
    "            completions = {}\n",
    "            for sample in knm.samples():\n",
    "                if (sample[0], sample[1]) == (tokenized[-2], tokenized[-1]):\n",
    "                    completions[sample[2]] = knm.prob(sample)\n",
    "            if len(completions) == 0:\n",
    "                response = \"Can we talk about something else?\"\n",
    "            else:\n",
    "                best = max(\n",
    "                    completions.keys(), key=(lambda key: completions[key])\n",
    "                )\n",
    "                tokenized += [best]\n",
    "                response = \" \".join(tokenized)\n",
    "\n",
    "        return response\n",
    "\n",
    "    print(complete(\"The President of the United\"))\n",
    "    print(complete(\"This election year will\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Can we talk about something else?'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete(\"The President\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = PickledCorpusReader('../ATAwP/corpus')\n",
    "tokens = [''.join(word) for word in corpus.words()]\n",
    "vocab = Counter(tokens)\n",
    "sents = list([word[0] for word in sent] for sent in corpus.sents())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = count_ngrams(3, vocab, sents)\n",
    "knm = KneserNeyModel(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = \"The President of the United\"\n",
    "tokenized = nltk.word_tokenize(input_text)\n",
    "len(tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "completions = {}\n",
    "for sample in knm.samples():\n",
    "    if (sample[0], sample[1]) == (tokenized[-2], tokenized[-1]):\n",
    "        completions[sample[2]] = knm.prob(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('<s>', '<s>', '<UNK>')\n",
      "('<s>', '<UNK>', '<UNK>')\n",
      "('<UNK>', '<UNK>', '<UNK>')\n",
      "('<UNK>', '<UNK>', '</s>')\n",
      "('<UNK>', '</s>', '</s>')\n",
      "('<s>', '<UNK>', '</s>')\n",
      "('<s>', '<s>', '</s>')\n",
      "('<s>', '</s>', '</s>')\n",
      "('<UNK>', '<UNK>', 'CNN')\n",
      "('<UNK>', 'CNN', '<UNK>')\n",
      "('CNN', '<UNK>', '<UNK>')\n",
      "('<UNK>', '<UNK>', '+$')\n",
      "('<UNK>', '+$', '<UNK>')\n",
      "('+$', '<UNK>', '<UNK>')\n",
      "('<UNK>', '<UNK>', '..')\n",
      "('<UNK>', '..', '<UNK>')\n",
      "('..', '<UNK>', '<UNK>')\n",
      "('<UNK>', '..', '</s>')\n",
      "('..', '</s>', '</s>')\n",
      "('<UNK>', '<UNK>', '::')\n",
      "('<UNK>', '::', '<UNK>')\n",
      "('::', '<UNK>', '<UNK>')\n",
      "('<UNK>', '<UNK>', '/$')\n",
      "('<UNK>', '/$', '<UNK>')\n",
      "('/$', '<UNK>', '<UNK>')\n",
      "('<UNK>', '<UNK>', 'ADT')\n",
      "('<UNK>', 'ADT', '<UNK>')\n",
      "('ADT', '<UNK>', '<UNK>')\n",
      "('<s>', '<s>', '::')\n",
      "('<s>', '::', '</s>')\n",
      "('::', '</s>', '</s>')\n",
      "('<UNK>', 'CNN', '</s>')\n",
      "('CNN', '</s>', '</s>')\n",
      "('<UNK>', '<UNK>', '\"$')\n",
      "('<UNK>', '\"$', '<UNK>')\n",
      "('\"$', '<UNK>', '<UNK>')\n",
      "('<s>', '<s>', 'CNN')\n",
      "('<s>', 'CNN', '<UNK>')\n",
      "('<s>', '<UNK>', 'CNN')\n",
      "('CNN', '<UNK>', '</s>')\n",
      "('<UNK>', '<UNK>', '))')\n",
      "('<UNK>', '))', '</s>')\n",
      "('))', '</s>', '</s>')\n",
      "('<UNK>', '<UNK>', '$$')\n",
      "('<UNK>', '$$', '<UNK>')\n",
      "('$$', '<UNK>', '<UNK>')\n"
     ]
    }
   ],
   "source": [
    "for sample in knm.samples():\n",
    "    print(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm, that doesn't seem to be working :("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
