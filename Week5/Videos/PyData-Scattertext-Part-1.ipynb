{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Scattertext\n",
    "\n",
    "## @jasonkessler\n",
    "\n",
    "https://github.com/JasonKessler/scattertext\n",
    "\n",
    "\n",
    "\n",
    "Cite as:\n",
    "Jason S. Kessler. Scattertext: a Browser-Based Tool for Visualizing how Corpora Differ. Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (ACL): System Demonstrations. 2017.\n",
    "\n",
    "Link to preprint: https://arxiv.org/abs/1703.00565\n",
    "\n",
    "`\n",
    "@article{kessler2017scattertext,\n",
    "  author    = {Kessler, Jason S.},\n",
    "  title     = {Scattertext: a Browser-Based Tool for Visualizing how Corpora Differ},\n",
    "  booktitle = {ACL System Demonstrations},\n",
    "  year      = {2017},\n",
    "}\n",
    "`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install scattertext agefromname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:98% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import scattertext as st\n",
    "import re, io\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import rankdata, hmean, norm\n",
    "import spacy\n",
    "import os, pkgutil, json, urllib\n",
    "from urllib.request import urlopen\n",
    "from IPython.display import IFrame\n",
    "from IPython.core.display import display, HTML\n",
    "from scattertext import CorpusFromPandas, produce_scattertext_explorer\n",
    "display(HTML(\"<style>.container { width:98% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nlp = spacy.load('en')\n",
    "# If this doesn't work, please uncomment the following line and use a regex-based parser instead\n",
    "nlp = st.whitespace_nlp_with_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grab the 2012 political convention data set and preview it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "convention_df = st.SampleCorpora.ConventionData2012.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "party                                               democrat\n",
       "text       Thank you. Thank you. Thank you. Thank you so ...\n",
       "speaker                                         BARACK OBAMA\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convention_df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document Count\n",
      "party\n",
      "democrat      123\n",
      "republican     66\n",
      "Name: text, dtype: int64\n",
      "Word Count\n"
     ]
    }
   ],
   "source": [
    "print(\"Document Count\")\n",
    "print(convention_df.groupby('party')['text'].count())\n",
    "print(\"Word Count\")\n",
    "convention_df.groupby('party').apply(lambda x: x.text.apply(lambda x: len(x.split())).sum())\n",
    "convention_df['parsed'] = convention_df.text.apply(nlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Turn it into a Scattertext corpus, and have spaCy parse it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = st.CorpusFromParsedDocuments(convention_df, category_col='party', parsed_col='parsed').build()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scattertext has some functions to find how associated words are with categories \n",
    "# I've reworded this section since the talk\n",
    "## Lots of ways to do this. I'm partial to a novel technique called Scaled F-Score\n",
    "# Intutition:\n",
    "### Associatied terms have a *relatively* high category-specific precision and category-specific term frequency (i.e., % of terms in category are term)\n",
    "### Take the harmonic mean of precision and frequency (both have to be high)\n",
    "### Hyper-parameters are pretty much universal (beta and transformation function)\n",
    "\n",
    "Given a word $w_i \\in W$ and a category $c_j \\in C$, define the precision of the word $w_i$ wrt to a category as:\n",
    "$$ \\mbox{prec}(w_i, c_j) = \\frac{\\#(w_i, c_j)}{\\sum_{c \\in C} \\#(w_i, c)}. $$\n",
    "\n",
    "The function $\\#(w_i, c_j)$ represents either the number of times $w_i$ occurs in a document labeled with the category $c_j$ or the number of documents labeled $c_j$ which contain $w_i$.\n",
    "\n",
    "Similarly, define the frequency a word occurs in the category as:\n",
    "\n",
    "$$ \\mbox{freq}(w_i, c_j) = \\frac{\\#(w_i, c_j)}{\\sum_{w \\in W} \\#(w, c_j)}. $$\n",
    "\n",
    "The F-Score of these two values is defined as:\n",
    "\n",
    "$$ \\mathcal{F}_\\beta(\\mbox{prec}, \\mbox{freq}) = (1 + \\beta^2) \\frac{\\mbox{prec} \\cdot \\mbox{freq}}{\\beta^2 \\cdot \\mbox{prec} + \\mbox{freq}}. $$\n",
    "\n",
    "$\\beta \\in \\mathcal{R}^+$ is a scaling factor where frequency is favored if $\\beta < 1$, precision if $\\beta > 1$, and both are equally weighted if $\\beta = 1$. F-Score is equivalent to the harmonic mean where $\\beta = 1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>democrat freq</th>\n",
       "      <th>republican freq</th>\n",
       "      <th>dem_precision</th>\n",
       "      <th>dem_freq_pct</th>\n",
       "      <th>dem_hmean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>3400</td>\n",
       "      <td>2534</td>\n",
       "      <td>0.572969</td>\n",
       "      <td>0.022364</td>\n",
       "      <td>0.043049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>2704</td>\n",
       "      <td>2236</td>\n",
       "      <td>0.547368</td>\n",
       "      <td>0.017786</td>\n",
       "      <td>0.034453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>2341</td>\n",
       "      <td>1668</td>\n",
       "      <td>0.583936</td>\n",
       "      <td>0.015399</td>\n",
       "      <td>0.030006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>1602</td>\n",
       "      <td>1349</td>\n",
       "      <td>0.542867</td>\n",
       "      <td>0.010538</td>\n",
       "      <td>0.020674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>of</th>\n",
       "      <td>1568</td>\n",
       "      <td>1379</td>\n",
       "      <td>0.532067</td>\n",
       "      <td>0.010314</td>\n",
       "      <td>0.020236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>that</th>\n",
       "      <td>1400</td>\n",
       "      <td>1052</td>\n",
       "      <td>0.570962</td>\n",
       "      <td>0.009209</td>\n",
       "      <td>0.018125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>we</th>\n",
       "      <td>1320</td>\n",
       "      <td>1146</td>\n",
       "      <td>0.535280</td>\n",
       "      <td>0.008683</td>\n",
       "      <td>0.017088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in</th>\n",
       "      <td>1294</td>\n",
       "      <td>988</td>\n",
       "      <td>0.567046</td>\n",
       "      <td>0.008512</td>\n",
       "      <td>0.016772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <td>1105</td>\n",
       "      <td>858</td>\n",
       "      <td>0.562914</td>\n",
       "      <td>0.007268</td>\n",
       "      <td>0.014352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s</th>\n",
       "      <td>1053</td>\n",
       "      <td>641</td>\n",
       "      <td>0.621606</td>\n",
       "      <td>0.006926</td>\n",
       "      <td>0.013700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      democrat freq  republican freq  dem_precision  dem_freq_pct  dem_hmean\n",
       "term                                                                        \n",
       "the            3400             2534       0.572969      0.022364   0.043049\n",
       "and            2704             2236       0.547368      0.017786   0.034453\n",
       "to             2341             1668       0.583936      0.015399   0.030006\n",
       "a              1602             1349       0.542867      0.010538   0.020674\n",
       "of             1568             1379       0.532067      0.010314   0.020236\n",
       "that           1400             1052       0.570962      0.009209   0.018125\n",
       "we             1320             1146       0.535280      0.008683   0.017088\n",
       "in             1294              988       0.567046      0.008512   0.016772\n",
       "i              1105              858       0.562914      0.007268   0.014352\n",
       "s              1053              641       0.621606      0.006926   0.013700"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term_freq_df = corpus.get_term_freq_df()\n",
    "term_freq_df['dem_precision'] = term_freq_df['democrat freq'] * 1./(term_freq_df['democrat freq'] + term_freq_df['republican freq'])\n",
    "term_freq_df['dem_freq_pct'] = term_freq_df['democrat freq'] * 1./term_freq_df['democrat freq'].sum()\n",
    "term_freq_df['dem_hmean'] = term_freq_df.apply(lambda x: (hmean([x['dem_precision'], x['dem_freq_pct']])\n",
    "                                                                   if x['dem_precision'] > 0 and x['dem_freq_pct'] > 0 \n",
    "                                                                   else 0), axis=1)                                                        \n",
    "term_freq_df.sort_values(by='dem_hmean', ascending=False).iloc[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution:\n",
    "### Take the normal CDF of precision and frequency percentage scores, which will fall between 0 and 1, which scales and standardizes both scores.\n",
    "\n",
    "Define the the Normal CDF as:\n",
    "\n",
    "$$ \\Phi(z) = \\int_{-\\infty}^z \\mathcal{N}(x; \\mu, \\sigma^2)\\ \\mathrm{d}x.$$\n",
    "\n",
    "Where $ \\mathcal{N} $ is the PDF of the Normal distribution, $\\mu$ is the mean, and $\\sigma^2$ is the variance.\n",
    "\n",
    "$\\Phi$ is used to scale and standardize the precisions and frequencies, and place them on the same scale $[0,1]$.\n",
    "\n",
    "Now we can define Scaled F-Score as the harmonic mean of the Normal CDF transformed frequency and precision:\n",
    "\n",
    "$$ \\mathcal{S}_{\\beta}(w_i, c_j) = \\mathcal{F}_{\\beta}(\\Phi(\\mbox{prec}(w_i, c_j)), \\Phi(\\mbox{freq}(w_i, c_j))).$$\n",
    "\n",
    "$\\mu$ and $\\sigma^2$ are defined separately as the mean and variance of precision and frequency.\n",
    "\n",
    "A $\\beta$ of 0.5 is recommended and is the default value in Scattertext.\n",
    "\n",
    "Note that any function with the range of $[0,1]$ (this includes the identity function) may be used in place of $\\Phi$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>democrat freq</th>\n",
       "      <th>republican freq</th>\n",
       "      <th>dem_precision</th>\n",
       "      <th>dem_freq_pct</th>\n",
       "      <th>dem_hmean</th>\n",
       "      <th>dem_precision_normcdf</th>\n",
       "      <th>dem_freq_pct_normcdf</th>\n",
       "      <th>dem_scaled_f_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>middle class</th>\n",
       "      <td>152</td>\n",
       "      <td>19</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001997</td>\n",
       "      <td>0.768254</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.868941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auto</th>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>0.000487</td>\n",
       "      <td>0.836306</td>\n",
       "      <td>0.888460</td>\n",
       "      <td>0.861594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fair</th>\n",
       "      <td>45</td>\n",
       "      <td>3</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.000296</td>\n",
       "      <td>0.000592</td>\n",
       "      <td>0.799786</td>\n",
       "      <td>0.933269</td>\n",
       "      <td>0.861387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>insurance</th>\n",
       "      <td>54</td>\n",
       "      <td>6</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.000355</td>\n",
       "      <td>0.000710</td>\n",
       "      <td>0.775696</td>\n",
       "      <td>0.965474</td>\n",
       "      <td>0.860242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forward</th>\n",
       "      <td>106</td>\n",
       "      <td>16</td>\n",
       "      <td>0.868852</td>\n",
       "      <td>0.000697</td>\n",
       "      <td>0.001393</td>\n",
       "      <td>0.754494</td>\n",
       "      <td>0.999870</td>\n",
       "      <td>0.860022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>president barack</th>\n",
       "      <td>47</td>\n",
       "      <td>4</td>\n",
       "      <td>0.921569</td>\n",
       "      <td>0.000309</td>\n",
       "      <td>0.000618</td>\n",
       "      <td>0.789747</td>\n",
       "      <td>0.941925</td>\n",
       "      <td>0.859149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <td>161</td>\n",
       "      <td>25</td>\n",
       "      <td>0.865591</td>\n",
       "      <td>0.001059</td>\n",
       "      <td>0.002115</td>\n",
       "      <td>0.752213</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.858587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>middle</th>\n",
       "      <td>168</td>\n",
       "      <td>28</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.001105</td>\n",
       "      <td>0.002207</td>\n",
       "      <td>0.746253</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.854691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the middle</th>\n",
       "      <td>98</td>\n",
       "      <td>17</td>\n",
       "      <td>0.852174</td>\n",
       "      <td>0.000645</td>\n",
       "      <td>0.001288</td>\n",
       "      <td>0.742713</td>\n",
       "      <td>0.999624</td>\n",
       "      <td>0.852228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medicare</th>\n",
       "      <td>85</td>\n",
       "      <td>15</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.000559</td>\n",
       "      <td>0.001117</td>\n",
       "      <td>0.741156</td>\n",
       "      <td>0.998202</td>\n",
       "      <td>0.850686</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  democrat freq  republican freq  dem_precision  dem_freq_pct  \\\n",
       "term                                                                            \n",
       "middle class                152               19       0.888889      0.001000   \n",
       "auto                         37                0       1.000000      0.000243   \n",
       "fair                         45                3       0.937500      0.000296   \n",
       "insurance                    54                6       0.900000      0.000355   \n",
       "forward                     106               16       0.868852      0.000697   \n",
       "president barack             47                4       0.921569      0.000309   \n",
       "class                       161               25       0.865591      0.001059   \n",
       "middle                      168               28       0.857143      0.001105   \n",
       "the middle                   98               17       0.852174      0.000645   \n",
       "medicare                     85               15       0.850000      0.000559   \n",
       "\n",
       "                  dem_hmean  dem_precision_normcdf  dem_freq_pct_normcdf  \\\n",
       "term                                                                       \n",
       "middle class       0.001997               0.768254              1.000000   \n",
       "auto               0.000487               0.836306              0.888460   \n",
       "fair               0.000592               0.799786              0.933269   \n",
       "insurance          0.000710               0.775696              0.965474   \n",
       "forward            0.001393               0.754494              0.999870   \n",
       "president barack   0.000618               0.789747              0.941925   \n",
       "class              0.002115               0.752213              1.000000   \n",
       "middle             0.002207               0.746253              1.000000   \n",
       "the middle         0.001288               0.742713              0.999624   \n",
       "medicare           0.001117               0.741156              0.998202   \n",
       "\n",
       "                  dem_scaled_f_score  \n",
       "term                                  \n",
       "middle class                0.868941  \n",
       "auto                        0.861594  \n",
       "fair                        0.861387  \n",
       "insurance                   0.860242  \n",
       "forward                     0.860022  \n",
       "president barack            0.859149  \n",
       "class                       0.858587  \n",
       "middle                      0.854691  \n",
       "the middle                  0.852228  \n",
       "medicare                    0.850686  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def normcdf(x):\n",
    "    return norm.cdf(x, x.mean(), x.std())\n",
    "term_freq_df['dem_precision_normcdf'] = normcdf(term_freq_df['dem_precision'])\n",
    "term_freq_df['dem_freq_pct_normcdf'] = normcdf(term_freq_df['dem_freq_pct'])\n",
    "term_freq_df['dem_scaled_f_score'] = hmean([term_freq_df['dem_precision_normcdf'], term_freq_df['dem_freq_pct_normcdf']])\n",
    "term_freq_df.sort_values(by='dem_scaled_f_score', ascending=False).iloc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>democrat freq</th>\n",
       "      <th>republican freq</th>\n",
       "      <th>dem_precision</th>\n",
       "      <th>dem_freq_pct</th>\n",
       "      <th>dem_hmean</th>\n",
       "      <th>dem_precision_normcdf</th>\n",
       "      <th>dem_freq_pct_normcdf</th>\n",
       "      <th>dem_scaled_f_score</th>\n",
       "      <th>dem_corner_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>auto</th>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>0.000487</td>\n",
       "      <td>0.836306</td>\n",
       "      <td>0.888460</td>\n",
       "      <td>0.861594</td>\n",
       "      <td>0.919662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>america forward</th>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>0.000368</td>\n",
       "      <td>0.836306</td>\n",
       "      <td>0.816177</td>\n",
       "      <td>0.826119</td>\n",
       "      <td>0.919631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auto industry</th>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>0.000316</td>\n",
       "      <td>0.836306</td>\n",
       "      <td>0.776309</td>\n",
       "      <td>0.805191</td>\n",
       "      <td>0.919607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>insurance companies</th>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>0.000316</td>\n",
       "      <td>0.836306</td>\n",
       "      <td>0.776309</td>\n",
       "      <td>0.805191</td>\n",
       "      <td>0.919607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pell</th>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000151</td>\n",
       "      <td>0.000303</td>\n",
       "      <td>0.836306</td>\n",
       "      <td>0.765624</td>\n",
       "      <td>0.799405</td>\n",
       "      <td>0.919597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last week</th>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000145</td>\n",
       "      <td>0.000289</td>\n",
       "      <td>0.836306</td>\n",
       "      <td>0.754662</td>\n",
       "      <td>0.793389</td>\n",
       "      <td>0.919587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pell grants</th>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.836306</td>\n",
       "      <td>0.743431</td>\n",
       "      <td>0.787138</td>\n",
       "      <td>0.919574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>women s</th>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000132</td>\n",
       "      <td>0.000263</td>\n",
       "      <td>0.836306</td>\n",
       "      <td>0.731937</td>\n",
       "      <td>0.780648</td>\n",
       "      <td>0.919561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>platform</th>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000132</td>\n",
       "      <td>0.000263</td>\n",
       "      <td>0.836306</td>\n",
       "      <td>0.731937</td>\n",
       "      <td>0.780648</td>\n",
       "      <td>0.919561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coverage</th>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>0.000237</td>\n",
       "      <td>0.836306</td>\n",
       "      <td>0.708199</td>\n",
       "      <td>0.766939</td>\n",
       "      <td>0.919528</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     democrat freq  republican freq  dem_precision  \\\n",
       "term                                                                 \n",
       "auto                            37                0            1.0   \n",
       "america forward                 28                0            1.0   \n",
       "auto industry                   24                0            1.0   \n",
       "insurance companies             24                0            1.0   \n",
       "pell                            23                0            1.0   \n",
       "last week                       22                0            1.0   \n",
       "pell grants                     21                0            1.0   \n",
       "women s                         20                0            1.0   \n",
       "platform                        20                0            1.0   \n",
       "coverage                        18                0            1.0   \n",
       "\n",
       "                     dem_freq_pct  dem_hmean  dem_precision_normcdf  \\\n",
       "term                                                                  \n",
       "auto                     0.000243   0.000487               0.836306   \n",
       "america forward          0.000184   0.000368               0.836306   \n",
       "auto industry            0.000158   0.000316               0.836306   \n",
       "insurance companies      0.000158   0.000316               0.836306   \n",
       "pell                     0.000151   0.000303               0.836306   \n",
       "last week                0.000145   0.000289               0.836306   \n",
       "pell grants              0.000138   0.000276               0.836306   \n",
       "women s                  0.000132   0.000263               0.836306   \n",
       "platform                 0.000132   0.000263               0.836306   \n",
       "coverage                 0.000118   0.000237               0.836306   \n",
       "\n",
       "                     dem_freq_pct_normcdf  dem_scaled_f_score  \\\n",
       "term                                                            \n",
       "auto                             0.888460            0.861594   \n",
       "america forward                  0.816177            0.826119   \n",
       "auto industry                    0.776309            0.805191   \n",
       "insurance companies              0.776309            0.805191   \n",
       "pell                             0.765624            0.799405   \n",
       "last week                        0.754662            0.793389   \n",
       "pell grants                      0.743431            0.787138   \n",
       "women s                          0.731937            0.780648   \n",
       "platform                         0.731937            0.780648   \n",
       "coverage                         0.708199            0.766939   \n",
       "\n",
       "                     dem_corner_score  \n",
       "term                                   \n",
       "auto                         0.919662  \n",
       "america forward              0.919631  \n",
       "auto industry                0.919607  \n",
       "insurance companies          0.919607  \n",
       "pell                         0.919597  \n",
       "last week                    0.919587  \n",
       "pell grants                  0.919574  \n",
       "women s                      0.919561  \n",
       "platform                     0.919561  \n",
       "coverage                     0.919528  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term_freq_df['dem_corner_score'] = corpus.get_corner_scores('democrat')\n",
    "term_freq_df.sort_values(by='dem_corner_score', ascending=False).iloc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Democratic terms\n",
      "['middle class',\n",
      " 'forward',\n",
      " 'class',\n",
      " 'middle',\n",
      " 'the middle',\n",
      " 'pay',\n",
      " 'medicare',\n",
      " 'education',\n",
      " 'health',\n",
      " 'president obama']\n",
      "Top 10 Republican terms\n",
      "['government',\n",
      " 'administration',\n",
      " 'business',\n",
      " 'success',\n",
      " 'can do',\n",
      " 'story',\n",
      " 'unemployment',\n",
      " 'freedom',\n",
      " 'paul',\n",
      " 'do better']\n"
     ]
    }
   ],
   "source": [
    "term_freq_df = corpus.get_term_freq_df()\n",
    "term_freq_df['Republican Score'] = corpus.get_scaled_f_scores('republican')\n",
    "term_freq_df['Democratic Score'] = corpus.get_scaled_f_scores('democrat')\n",
    "print(\"Top 10 Democratic terms\")\n",
    "pprint(list(term_freq_df.sort_values(by='Democratic Score', ascending=False).index[:10]))\n",
    "print(\"Top 10 Republican terms\")\n",
    "pprint(list(term_freq_df.sort_values(by='Republican Score', ascending=False).index[:10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make and visualize chart, scale based on raw frequency.\n",
    "### - A word used 10 times by Republicans will be at position 10 on the on the x-axis \n",
    "### - This isn't very useful.  Everything but the most frequent terms are squished the lower-left corner\n",
    "### - The corner-distance scores are largely stopwords\n",
    "### - By default, color words by Scaled F-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "scale() takes from 1 to 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-1119561ffd3c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m html = produce_scattertext_explorer(corpus,\n\u001b[0m\u001b[0;32m      2\u001b[0m                                     \u001b[0mcategory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'democrat'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                                     \u001b[0mcategory_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Democratic'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                                     \u001b[0mnot_category_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Republican'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                                     \u001b[0mwidth_in_pixels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\scattertext\\__init__.py\u001b[0m in \u001b[0;36mproduce_scattertext_explorer\u001b[1;34m(corpus, category, category_name, not_category_name, protocol, pmi_threshold_coefficient, minimum_term_frequency, minimum_not_category_term_frequency, max_terms, filter_unigrams, height_in_pixels, width_in_pixels, max_snippets, max_docs_per_category, metadata, scores, x_coords, y_coords, original_x, original_y, rescale_x, rescale_y, singleScoreMode, sort_by_dist, reverse_sort_scores_for_not_category, use_full_doc, transform, jitter, gray_zero_scores, term_ranker, asian_mode, match_full_line, use_non_text_features, show_top_terms, show_characteristic, word_vec_use_p_vals, max_p_val, p_value_colors, term_significance, save_svg_button, x_label, y_label, d3_url, d3_scale_chromatic_url, pmi_filter_thresold, alternative_text_field, terms_to_include, semiotic_square, num_terms_semiotic_square, not_categories, neutral_categories, extra_categories, show_neutral, neutral_category_name, get_tooltip_content, x_axis_values, y_axis_values, x_axis_values_format, y_axis_values_format, color_func, term_scorer, show_axes, show_axes_and_cross_hairs, show_diagonal, use_global_scale, horizontal_line_y_position, vertical_line_x_position, show_cross_axes, show_extra, extra_category_name, censor_points, center_label_over_points, x_axis_labels, y_axis_labels, topic_model_term_lists, topic_model_preview_size, metadata_descriptions, vertical_lines, characteristic_scorer, term_colors, unified_context, show_category_headings, highlight_selected_category, include_term_category_counts, div_name, alternative_term_func, term_metadata, term_metadata_df, max_overlapping, include_all_contexts, show_corpus_stats, sort_doc_labels_by_name, enable_term_category_description, always_jump, get_custom_term_html, header_names, header_sorting_algos, ignore_categories, d3_color_scale, background_labels, tooltip_columns, tooltip_column_names, term_description_columns, term_description_column_names, term_word_in_term_description, color_column, color_score_column, label_priority_column, text_color_column, suppress_text_column, background_color, left_list_column, censor_point_column, right_order_column, line_coordinates, subword_encoding, use_offsets, return_data, return_scatterplot_structure)\u001b[0m\n\u001b[0;32m    592\u001b[0m         html_base = get_semiotic_square_html(num_terms_semiotic_square,\n\u001b[0;32m    593\u001b[0m                                              semiotic_square)\n\u001b[1;32m--> 594\u001b[1;33m     scatter_chart_data = scatter_chart_explorer.to_dict(\n\u001b[0m\u001b[0;32m    595\u001b[0m         \u001b[0mcategory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcategory\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    596\u001b[0m         \u001b[0mcategory_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcategory_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\scattertext\\ScatterChartExplorer.py\u001b[0m in \u001b[0;36mto_dict\u001b[1;34m(self, category, category_name, not_category_name, scores, metadata, max_docs_per_category, transform, alternative_text_field, title_case_names, not_categories, neutral_categories, extra_categories, neutral_category_name, extra_category_name, background_scorer, include_term_category_counts, use_offsets, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m             \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Excessive arguments passed to ScatterChartExplorer.to_dict: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 115\u001b[1;33m         json_data = ScatterChart.to_dict(self,\n\u001b[0m\u001b[0;32m    116\u001b[0m                                          \u001b[0mcategory\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m                                          \u001b[0mcategory_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcategory_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\scattertext\\ScatterChart.py\u001b[0m in \u001b[0;36mto_dict\u001b[1;34m(self, category, category_name, not_category_name, scores, transform, title_case_names, not_categories, neutral_categories, extra_categories, background_scorer, use_offsets, **kwargs)\u001b[0m\n\u001b[0;32m    328\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    329\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx_coords\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 330\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx_coords\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my_coords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_coordinates_from_transform_and_jitter_frequencies\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    331\u001b[0m                 \u001b[1;33m(\u001b[0m\u001b[0mcategory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnot_categories\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    332\u001b[0m             \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'x'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'y'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx_coords\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my_coords\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\scattertext\\ScatterChart.py\u001b[0m in \u001b[0;36m_get_coordinates_from_transform_and_jitter_frequencies\u001b[1;34m(self, category, df, other_categories, transform)\u001b[0m\n\u001b[0;32m    474\u001b[0m         \u001b[0mnot_counts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mc\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' freq'\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mother_categories\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    475\u001b[0m         \u001b[0mcounts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcategory\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' freq'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 476\u001b[1;33m         \u001b[0mx_data_raw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnot_counts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcounts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    477\u001b[0m         \u001b[0my_data_raw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcounts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnot_counts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    478\u001b[0m         \u001b[0mx_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_add_jitter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_data_raw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: scale() takes from 1 to 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "html = produce_scattertext_explorer(corpus,\n",
    "                                    category='democrat',\n",
    "                                    category_name='Democratic',\n",
    "                                    not_category_name='Republican',\n",
    "                                    width_in_pixels=1000,\n",
    "                                    minimum_term_frequency=5,\n",
    "                                    transform=st.Scalers.scale,\n",
    "                                    metadata=convention_df['speaker'])\n",
    "file_name = 'output/Conventions2012ScattertextScale.html'\n",
    "open(file_name, 'wb').write(html.encode('utf-8'))\n",
    "IFrame(src=file_name, width = 1200, height=700)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using log scales seems to help a bit, but blank space and stop words still dominate the graph\n",
    "### The chracteristic terms look much more informative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1200\"\n",
       "            height=\"700\"\n",
       "            src=\"output/Conventions2012ScattertextLog.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x143bce7a610>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html = st.produce_scattertext_explorer(corpus,\n",
    "                                       category='democrat',\n",
    "                                       category_name='Democratic',\n",
    "                                       not_category_name='Republican',\n",
    "                                       minimum_term_frequency=5,\n",
    "                                       width_in_pixels=1000,\n",
    "                                       transform=st.Scalers.log_scale_standardize)\n",
    "file_name = 'output/Conventions2012ScattertextLog.html'\n",
    "open(file_name, 'wb').write(html.encode('utf-8'))\n",
    "IFrame(src=file_name, width = 1200, height=700)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rank terms by frequency percentiles instead of raw frequenies.  \n",
    "### A term at the middle of the x-axis will be mentioned by Republicans at the median frequency.\n",
    "### This nicely distributes terms throughout the space\n",
    "### But, terms occuring with the same frequencies in both classes are stacked atop each other.\n",
    "### Can't mouseover points not at top of stack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1200\"\n",
       "            height=\"700\"\n",
       "            src=\"output/Conventions2012ScattertextRankData.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x143ba493a90>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html = produce_scattertext_explorer(corpus,\n",
    "                                    category='democrat',\n",
    "                                    category_name='Democratic',\n",
    "                                    not_category_name='Republican',\n",
    "                                    width_in_pixels=1000,\n",
    "                                    minimum_term_frequency=5,\n",
    "                                    transform=st.Scalers.percentile,\n",
    "                                    metadata=convention_df['speaker'])\n",
    "file_name = 'output/Conventions2012ScattertextRankData.html'\n",
    "open(file_name, 'wb').write(html.encode('utf-8'))\n",
    "IFrame(src=file_name, width = 1200, height=700)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One solution is to randomly jitter each point\n",
    "## Points don't leave enough space for many labels\n",
    "## Top terms laregely result of jitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1200\"\n",
       "            height=\"700\"\n",
       "            src=\"output/Conventions2012ScattertextRankDataJitter.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x143b93b4dc0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html = produce_scattertext_explorer(corpus,\n",
    "                                    category='democrat',\n",
    "                                    category_name='Democratic',\n",
    "                                    not_category_name='Republican',\n",
    "                                    width_in_pixels=1000,\n",
    "                                    jitter=0.1,\n",
    "                                    minimum_term_frequency=5,\n",
    "                                    transform=st.Scalers.percentile,\n",
    "                                    metadata=convention_df['speaker'])\n",
    "file_name = 'output/Conventions2012ScattertextRankDataJitter.html'\n",
    "open(file_name, 'wb').write(html.encode('utf-8'))\n",
    "IFrame(src=file_name, width = 1200, height=700)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The preferred solution is to fall back to alphabetic order among equally frequent terms\n",
    "## Lets you mouseover all points\n",
    "## Leaves a bit of room for labels\n",
    "## Top points may be slightly distorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1200\"\n",
       "            height=\"700\"\n",
       "            src=\"output/Conventions2012ScattertextRankDefault.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x143b93aaa90>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html = produce_scattertext_explorer(corpus,\n",
    "                                    category='democrat',\n",
    "                                    category_name='Democratic',\n",
    "                                    not_category_name='Republican',\n",
    "                                    width_in_pixels=1000,\n",
    "                                    minimum_term_frequency=5,\n",
    "                                    metadata=convention_df['speaker'],\n",
    "                                    term_significance = st.LogOddsRatioUninformativeDirichletPrior())\n",
    "file_name = 'output/Conventions2012ScattertextRankDefault.html'\n",
    "open(file_name, 'wb').write(html.encode('utf-8'))\n",
    "IFrame(src=file_name, width = 1200, height=700)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scattertext can also be used for alternative visualizations\n",
    "## Visualize L2-penalized logistic regression coefficients vs. log term frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(ar): \n",
    "    return (ar - ar.min()) / (ar.max() - ar.min())\n",
    "\n",
    "def zero_centered_scale(ar):\n",
    "    scores = np.zeros(len(ar))\n",
    "    scores[ar > 0] = scale(ar[ar > 0])\n",
    "    scores[ar < 0] = -scale(-ar[ar < 0])\n",
    "    return (scores + 1) / 2.\n",
    "\n",
    "frequencies_scaled = scale(np.log(term_freq_df.sum(axis=1).values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1200\"\n",
       "            height=\"700\"\n",
       "            src=\"output/L2vsLog.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x143996c4ee0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "scores = corpus.get_logreg_coefs('democrat',\n",
    "                                 LogisticRegression(penalty='l2', C=10, max_iter=10000, n_jobs=-1))\n",
    "scores_scaled = zero_centered_scale(scores)\n",
    "\n",
    "html = produce_scattertext_explorer(corpus,\n",
    "                                    category='democrat',\n",
    "                                    category_name='Democratic',\n",
    "                                    not_category_name='Republican',\n",
    "                                    minimum_term_frequency=5,\n",
    "                                    width_in_pixels=1000,\n",
    "                                    x_coords=frequencies_scaled,\n",
    "                                    y_coords=scores_scaled,\n",
    "                                    scores=scores,\n",
    "                                    sort_by_dist=False,\n",
    "                                    metadata=convention_df['speaker'],\n",
    "                                    x_label='Log frequency',\n",
    "                                    y_label='L2-Penalized Log Reg Coef')\n",
    "file_name = 'output/L2vsLog.html'\n",
    "open(file_name, 'wb').write(html.encode('utf-8'))\n",
    "IFrame(src=file_name, width = 1200, height=700)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We can see how this compares to Scaled F-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1200\"\n",
       "            height=\"700\"\n",
       "            src=\"output/SFSvsLog.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x143bbf38af0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html = produce_scattertext_explorer(corpus,\n",
    "                                    category='democrat',\n",
    "                                    category_name='Democratic',\n",
    "                                    not_category_name='Republican',\n",
    "                                    minimum_term_frequency=5,\n",
    "                                    width_in_pixels=1000,\n",
    "                                    x_coords=frequencies_scaled,\n",
    "                                    y_coords=corpus.get_scaled_f_scores('democrat', beta=0.5),\n",
    "                                    scores=corpus.get_scaled_f_scores('democrat', beta=0.5),\n",
    "                                    sort_by_dist=False,\n",
    "                                    metadata=convention_df['speaker'],\n",
    "                                    x_label='Log Frequency',\n",
    "                                    y_label='Scaled F-Score')\n",
    "file_name = 'output/SFSvsLog.html'\n",
    "open(file_name, 'wb').write(html.encode('utf-8'))\n",
    "IFrame(src=file_name, width = 1200, height=700)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Penalized log-odds-ratio has recently become popular recently\n",
    "\n",
    "Burt L. Monroe, Michael P. Colaresi, and Kevin M. Quinn. 2008. Fightin words: Lexical feature selection and evaluation for identifying the content of political conflict. Political Analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_df = corpus.get_term_freq_df().rename(columns={'democrat freq': 'y_dem', 'republican freq': 'y_rep'})\n",
    "a_w = 0.01\n",
    "y_i, y_j = freq_df['y_dem'].values, freq_df['y_rep'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_i, n_j = y_i.sum(), y_j.sum()\n",
    "a_0 = len(freq_df) * a_w\n",
    "delta_i_j = (  np.log((y_i + a_w) / (n_i + a_0 - y_i - a_w))\n",
    "                 - np.log((y_j + a_w) / (n_j + a_0 - y_j - a_w)))\n",
    "var_delta_i_j = ( 1./(y_i + a_w) + 1./(y_i + a_0 - y_i - a_w)\n",
    "                    + 1./(y_j + a_w) + 1./(n_j + a_0 - n_j - a_w))\n",
    "zeta_i_j = delta_i_j/np.sqrt(var_delta_i_j)\n",
    "max_abs_zeta = max(zeta_i_j.max(), -zeta_i_j.min())\n",
    "zeta_scaled_for_charting = ((((zeta_i_j > 0).astype(float) * (zeta_i_j/max_abs_zeta))*0.5 + 0.5)\n",
    "                            + ((zeta_i_j < 0).astype(float) * (zeta_i_j/max_abs_zeta) * 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1200\"\n",
       "            height=\"700\"\n",
       "            src=\"output/LOPriorvsLog.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x143b3224730>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html = produce_scattertext_explorer(corpus,\n",
    "                                    category='democrat',\n",
    "                                    category_name='Democratic',\n",
    "                                    not_category_name='Republican',\n",
    "                                    minimum_term_frequency=5,\n",
    "                                    width_in_pixels=1000,\n",
    "                                    x_coords=frequencies_scaled,\n",
    "                                    y_coords=zeta_scaled_for_charting,\n",
    "                                    scores=zeta_i_j,\n",
    "                                    sort_by_dist=False,\n",
    "                                    metadata=convention_df['speaker'],\n",
    "                                    x_label='Log Frequency',\n",
    "                                    y_label='Log Odds Ratio w/ Uninformative Prior (alpha_w=0.01)')\n",
    "file_name = 'output/LOPriorvsLog.html'\n",
    "open(file_name, 'wb').write(html.encode('utf-8'))\n",
    "IFrame(src=file_name, width = 1200, height=700)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## And finally, corner score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1200\"\n",
       "            height=\"700\"\n",
       "            src=\"output/CornervsLog.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x143bbf38070>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corner_scores = corpus.get_corner_scores('democrat')\n",
    "html = produce_scattertext_explorer(corpus,\n",
    "                                    category='democrat',\n",
    "                                    category_name='Democratic',\n",
    "                                    not_category_name='Republican',\n",
    "                                    minimum_term_frequency=5,\n",
    "                                    width_in_pixels=1000,\n",
    "                                    x_coords=frequencies_scaled,\n",
    "                                    y_coords=corner_scores,\n",
    "                                    scores=corner_scores,\n",
    "                                    sort_by_dist=False,\n",
    "                                    metadata=convention_df['speaker'],\n",
    "                                    x_label='Log Frequency',\n",
    "                                    y_label='Corner Scores')\n",
    "file_name = 'output/CornervsLog.html'\n",
    "open(file_name, 'wb').write(html.encode('utf-8'))\n",
    "IFrame(src=file_name, width = 1200, height=700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
