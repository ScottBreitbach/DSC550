{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1231e864-0c11-4de6-82e1-f3dbc4cee5e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "306f82b6-aad9-4ba4-84ca-fdfaf6f090df",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49b83d97-e780-4fad-b9b2-153cb0998f48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "# Use all processor cores\n",
    "from sklearnex import patch_sklearn\n",
    "patch_sklearn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78b47103-a3a6-4ecf-a1fb-65998c89b4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import jsonlines\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ffa1977-ffd9-427e-ac0d-fb7b6137d242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7.18 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Load JSON data into a list of dictionaries\n",
    "data = []\n",
    "with jsonlines.open('categorized-comments.jsonl') as reader:\n",
    "    for obj in reader.iter(type=dict, skip_invalid=True):\n",
    "        data.append(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e2e2b20-c5e2-4500-b4d3-ea276b6d4689",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sports</td>\n",
       "      <td>Barely better than Gabbert? He was significant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sports</td>\n",
       "      <td>Fuck the ducks and the Angels! But welcome to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sports</td>\n",
       "      <td>Should have drafted more WRs.\\n\\n- Matt Millen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sports</td>\n",
       "      <td>[Done](https://i.imgur.com/2YZ90pm.jpg)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sports</td>\n",
       "      <td>No!! NOO!!!!!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      cat                                                txt\n",
       "0  sports  Barely better than Gabbert? He was significant...\n",
       "1  sports  Fuck the ducks and the Angels! But welcome to ...\n",
       "2  sports  Should have drafted more WRs.\\n\\n- Matt Millen...\n",
       "3  sports            [Done](https://i.imgur.com/2YZ90pm.jpg)\n",
       "4  sports                                      No!! NOO!!!!!"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert data to DataFrame\n",
    "cat_comments_df = pd.DataFrame(data)\n",
    "cat_comments_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7553e8b3-3c8d-46f7-867a-37b9213f4731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The categories are:\n",
      " - sports\n",
      " - science_and_technology\n",
      " - video_games\n"
     ]
    }
   ],
   "source": [
    "# Check out the categories\n",
    "categories = cat_comments_df.cat.unique()\n",
    "print(\"The categories are:\")\n",
    "for category in categories:\n",
    "    print(\" -\", category)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253b5fc6-ce9c-4005-a15a-c637cd73d4ce",
   "metadata": {},
   "source": [
    "## Preprocess Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76fddcf9-6134-44da-8abb-ff47444a2817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import re\n",
    "import sys\n",
    "import unicodedata\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "# from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4559db24-de8c-444f-bd97-0d30dcc13103",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = cat_comments_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d3ee2b3-8966-4ae7-a86f-44b7b57ad48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d698098-5dd2-4c9c-a5ef-94234e6fb108",
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation_dict = dict.fromkeys(i for i in range(sys.maxunicode) \n",
    "                            if unicodedata.category(chr(i)).startswith('P'))\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "stopwords_dict = Counter(stop_words)\n",
    "\n",
    "def cleanText(string):\n",
    "    '''Processes string and returns cleaned up list of words'''\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    string = string.lower()\n",
    "    \n",
    "    # Remove URLs\n",
    "    string = re.sub(r'http\\S+', '', string)\n",
    "    \n",
    "    # Remove punctuation\n",
    "    string = string.translate(punctuation_dict)\n",
    "    \n",
    "    # Remove newlines\n",
    "    string = string.replace(\"\\n\", \" \")\n",
    "    \n",
    "    # Remove stopwords\n",
    "    string = [word for word in string.split() if word not in stopwords_dict]\n",
    "    \n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1ba0db7-7e3b-4a6c-966c-1c481af67603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 15.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Clean up the text in the 'txt' column\n",
    "df.txt = df.txt.apply(lambda string: cleanText(string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f06f261-0f6d-4d90-aa48-509a45ce9ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "60885b0a-daf2-48da-b20d-5cfffacceb2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Apply PorterStemmer\n",
    "porter = PorterStemmer()\n",
    "\n",
    "df['txt_stems'] = df.txt.apply(lambda words: [porter.stem(word) for word in words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f44c5fce-b487-4117-ab91-359de4db9ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482e694d-c472-4e26-9603-b959c42e3b86",
   "metadata": {},
   "source": [
    "## Prepare Text for Model-Building\n",
    "### **--COMMENT ALL THIS CODE--**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f8c7270-8e9f-4e7a-8bd9-8b684e894903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import nltk\n",
    "from nltk import pos_tag\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c84717f-c95c-4711-9e15-103ab1a01763",
   "metadata": {},
   "source": [
    "### Back up, let's sample to equal sized groups:\n",
    "https://stackoverflow.com/questions/41345289/getting-a-random-sample-in-python-dataframe-by-category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ee2d0af-134c-4a8d-806c-b07695518ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_group = df.groupby('cat', as_index=False, group_keys=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "91907ef1-f3bb-4ae5-a23a-eefaa9525a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "balancedDF = cat_group.apply(lambda s: s.sample(25000, replace=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d2546a39-50cf-40b9-b34b-4b4aefa1ecff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "science_and_technology    25000\n",
       "video_games               25000\n",
       "sports                    25000\n",
       "Name: cat, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balancedDF.cat.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514825d1-37ee-4e7d-a3b3-cba23b4ee791",
   "metadata": {},
   "source": [
    "### Convert to a word-count vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c8810c76-81c7-4b6c-842f-8d9a7d4bb943",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a6709d15-1656-40c9-b33c-26196c32e296",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data, string = [], \" \"\n",
    "\n",
    "for text in balancedDF.txt_stems:\n",
    "    text_data.append(string.join(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "44788a99-66ea-4d48-80eb-4835c3967c64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.39 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<75000x40984 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 958962 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Word-count vector as a sparse matrix\n",
    "bal_sparseWCV = count.fit_transform(text_data)\n",
    "bal_sparseWCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a1168cc7-67e0-488a-bf83-b6eec97aaf83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75000, 40984)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bal_sparseWCV.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5287bc2c-f947-44cb-8548-dfc64dfcf138",
   "metadata": {},
   "source": [
    "## NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d3b53ce5-89de-41a1-ae37-45248ad14ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up data and labels\n",
    "X = bal_sparseWCV\n",
    "y = balancedDF.cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7cf8b4cd-98ff-40cd-a625-a2f745a6daff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75000,)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e1d51d31-6043-4404-969f-8c4b7048b63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "ct = ColumnTransformer([('Country', OneHotEncoder(), [0])], remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bd5a27d4-3bec-4590-b4f0-c142db3ea31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "oneHotEnc = OneHotEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b24516eb-b53e-4f6d-bbbe-957ea0e0ebf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# oneHotEnc.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6207e0ca-0c27-4fa2-bfff-ff4d6fd3d854",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "mlb  = MultiLabelBinarizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cc7d69aa-741d-4f66-bf31-66df6b8d5ee1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiLabelBinarizer()"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlb.fit([y])\n",
    "mlb.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "26c4d73a-a278-4b59-80b0-c6e45a098098",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y = mlb.transform([y])\n",
    "test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6aece254-5a51-4845-955d-19417694d84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count = CountVectorizer(vocabulary=)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "348b6544-5f56-4ac8-867a-47b92461e270",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75000, 3)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y = count.fit_transform(y)\n",
    "test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d0d4046d-8869-4da0-b760-05c7cfd4a6c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<75000x3 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 75000 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7734c61b-adb9-42ad-b18b-99177555e8f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['science_and_technology', 'sports', 'video_games']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf81d3b-6607-49cd-bde8-5e9de23fd0aa",
   "metadata": {},
   "source": [
    "##### ~~FINALLY!~~ -- Well dang \"wrong order\": https://www.tensorflow.org/api_docs/python/tf/sparse/reorder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e5a0b2da-d911-4eb7-87a6-217837a24791",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_sparse = count.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "d1da8a95-3e16-415f-bf33-9dca796581c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.sparse.reorder(y_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "54175f3c-2299-42fc-ada7-a830366e363e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75000, 2)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_sparse[:, :2].toarray().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "6e135d4c-3f32-454a-a361-a413cf79cbbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0]], dtype=int64)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_sparse[:5, :2].toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "dabe9d8b-d863-424f-94d6-d8ebee5c9b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_sparse = y_sparse[:, :2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "75c59f01-9315-49c9-bd3b-0efd91d76b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "0e23b6c2-ac93-4059-92d1-83c9c4229028",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.fit(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "d698e470-1d40-449d-9620-be6b8712a308",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_lEnc = le.transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "b2aa576e-2aaf-48ab-b3e3-2f5e48338a12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75000,)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_lEnc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "7f834c74-91e1-4b3b-a63a-f43ffefa936c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_lEnc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "4399f5ab-0774-4582-b0f6-cb5cc0a9d81d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 2, 2, 2])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_lEnc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559d3c29-c5da-4674-a4b7-40ac1339635a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4e37024f-729b-4038-8ae8-66d2d81a6680",
   "metadata": {},
   "source": [
    "## try this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "4561449e-c4f9-48ad-903e-d1921fcb523e",
   "metadata": {},
   "outputs": [],
   "source": [
    "testDF = cat_comments_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "865e4beb-a7e6-4be1-a19e-9a1053cf3fdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sports</td>\n",
       "      <td>Barely better than Gabbert? He was significant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sports</td>\n",
       "      <td>Fuck the ducks and the Angels! But welcome to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sports</td>\n",
       "      <td>Should have drafted more WRs.\\n\\n- Matt Millen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sports</td>\n",
       "      <td>[Done](https://i.imgur.com/2YZ90pm.jpg)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sports</td>\n",
       "      <td>No!! NOO!!!!!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      cat                                                txt\n",
       "0  sports  Barely better than Gabbert? He was significant...\n",
       "1  sports  Fuck the ducks and the Angels! But welcome to ...\n",
       "2  sports  Should have drafted more WRs.\\n\\n- Matt Millen...\n",
       "3  sports            [Done](https://i.imgur.com/2YZ90pm.jpg)\n",
       "4  sports                                      No!! NOO!!!!!"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "fe8d52d0-17a5-43ac-9fc1-7300dbb7aee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_group = testDF.groupby('cat', as_index=False, group_keys=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "4a865b88-22e4-44d8-a0c2-d2195fe62cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "bal_testDF = cat_group.apply(lambda s: s.sample(25000, replace=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "ef4b0d2c-4b80-45da-810f-4044f3a46ecc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "science_and_technology    25000\n",
       "video_games               25000\n",
       "sports                    25000\n",
       "Name: cat, dtype: int64"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bal_testDF.cat.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "d3f66ef4-a73d-48d1-b7a0-7cfb7b8cbaf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75000, 2)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bal_testDF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "b4759063-bad4-42f6-a500-a7a81b944518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove URLs\n",
    "bal_testDF.txt = bal_testDF.txt.apply(lambda text: re.sub(r'http\\S+', '', text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "e66fdeaf-c8f5-4294-be23-7896083bba40",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = CountVectorizer(strip_accents='unicode', stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "55769f1a-5d68-4b60-b19b-25c0cba3d664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.66 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_X = count.fit_transform(bal_testDF.txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "ecda2e60-735f-41c6-9fa6-319f1d65407b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75000, 44297)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "7f1d161d-844f-494c-aa49-4f2145dc1cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y = bal_testDF.cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "e5d3abd3-a74a-4496-ae25-fb8292fea77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "d280be9e-2e53-4bd2-80da-424b61869671",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y = le.fit_transform(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "6d074a0a-4b86-4001-9815-c39a22add77b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75000,)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "38d7d579-9089-45d2-a397-a6819eb09eca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 2, 2, 2])"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "1c5fcc38-e012-477c-84ff-9406057330b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([75000, 44297])"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X_tf_reordered.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78cab60e-8772-4ad3-9a35-66930f0f88c2",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "7cbbf674-c26d-4d13-bf21-d505b886b137",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "4ccfa3b0-42d2-4e40-9579-11aebcbc8464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 27.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(test_X, test_y) # Default is 1/4 --> test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0e5628-9407-4593-81ca-68d9d1ddb13a",
   "metadata": {},
   "source": [
    "## 2. Define Keras Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "fdf5d7dc-1ae9-430e-93e4-4ce840d9dc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the Keras libraries and packages\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "0c5bb6a3-57ba-48ac-9f39-69358619970b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75000, 40984)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "3717e9d7-66d0-4001-bc61-4433d24a5455",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75000, 2)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y_sparse.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "b67ce524-352b-41d7-adb9-c93882fc3486",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75000,)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y_lEnc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "44d2b2ab-049c-4f6d-abfe-2962732c7536",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44297"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "4f415375-1b8a-4034-8676-477642973554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the keras model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=X_train.shape[1], activation='relu')) # \n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db15b537-447a-42d2-9ad5-735dede7a8c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c240276f-e2df-4bef-af5d-2d7f5373e2ba",
   "metadata": {},
   "source": [
    "## 3. Compile Keras Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "5d16ede3-ecd0-41f5-9f9b-d23a37f37fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "c4a8f62c-7d7b-4673-9959-804382e4bda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the keras model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) #  optimizer=RMSprop(lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08f5e14-57de-4cef-bf57-e02ca90914a6",
   "metadata": {},
   "source": [
    "## 4. Fit Keras Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "e7cfe420-c776-4af1-8789-5ac754c32908",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "52f3dd7c-bcd8-450b-b88a-2e9cfc308432",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "918e167f-0d5a-430d-a9da-67976c627aac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56250, 44297)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "21676eef-b4b1-424e-98c7-cf4ae5d22aee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56250,)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "c8eadb71-efb8-41d0-943d-6c90ac652ca7",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "indices[2] = [0,23236] is out of order. Many sparse ops require sorted indices.\n    Use `tf.sparse.reorder` to create a correctly ordered copy.\n\n [Op:SerializeManySparse]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1047\u001b[0m          \u001b[0mtraining_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRespectCompiledTrainableState\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1048\u001b[0m       \u001b[1;31m# Creates a `tf.data.Dataset` and handles batch and epoch iteration.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1049\u001b[1;33m       data_handler = data_adapter.DataHandler(\n\u001b[0m\u001b[0;32m   1050\u001b[0m           \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1051\u001b[0m           \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[0;32m   1103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m     \u001b[0madapter_cls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mselect_data_adapter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1105\u001b[1;33m     self._adapter = adapter_cls(\n\u001b[0m\u001b[0;32m   1106\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1107\u001b[0m         \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, steps, shuffle, **kwargs)\u001b[0m\n\u001b[0;32m    571\u001b[0m     \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpack_x_y_sample_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    572\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 573\u001b[1;33m     \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDatasetV2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_tensor_slices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    574\u001b[0m     \u001b[0mnum_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    575\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36mfrom_tensor_slices\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    680\u001b[0m       \u001b[0mDataset\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    681\u001b[0m     \"\"\"\n\u001b[1;32m--> 682\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mTensorSliceDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    683\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    684\u001b[0m   \u001b[1;32mclass\u001b[0m \u001b[0m_GeneratorState\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, element)\u001b[0m\n\u001b[0;32m   3001\u001b[0m     \u001b[0melement\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melement\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3002\u001b[0m     \u001b[0mbatched_spec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype_spec_from_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melement\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3003\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tensors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_batched_tensor_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatched_spec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0melement\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3004\u001b[0m     self._structure = nest.map_structure(\n\u001b[0;32m   3005\u001b[0m         lambda component_spec: component_spec._unbatch(), batched_spec)  # pylint: disable=protected-access\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\util\\structure.py\u001b[0m in \u001b[0;36mto_batched_tensor_list\u001b[1;34m(element_spec, element)\u001b[0m\n\u001b[0;32m    348\u001b[0m   \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    349\u001b[0m   \u001b[1;31m# pylint: disable=g-long-lambda\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 350\u001b[1;33m   return _to_tensor_list_helper(\n\u001b[0m\u001b[0;32m    351\u001b[0m       lambda state, spec, component: state + spec._to_batched_tensor_list(\n\u001b[0;32m    352\u001b[0m           component), element_spec, element)\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\util\\structure.py\u001b[0m in \u001b[0;36m_to_tensor_list_helper\u001b[1;34m(encode_fn, element_spec, element)\u001b[0m\n\u001b[0;32m    323\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mencode_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mspec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcomponent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 325\u001b[1;33m   return functools.reduce(\n\u001b[0m\u001b[0;32m    326\u001b[0m       reduce_fn, zip(nest.flatten(element_spec), nest.flatten(element)), [])\n\u001b[0;32m    327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\util\\structure.py\u001b[0m in \u001b[0;36mreduce_fn\u001b[1;34m(state, value)\u001b[0m\n\u001b[0;32m    321\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mreduce_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m     \u001b[0mspec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcomponent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 323\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mencode_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mspec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcomponent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    324\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m   return functools.reduce(\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\util\\structure.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(state, spec, component)\u001b[0m\n\u001b[0;32m    349\u001b[0m   \u001b[1;31m# pylint: disable=g-long-lambda\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    350\u001b[0m   return _to_tensor_list_helper(\n\u001b[1;32m--> 351\u001b[1;33m       lambda state, spec, component: state + spec._to_batched_tensor_list(\n\u001b[0m\u001b[0;32m    352\u001b[0m           component), element_spec, element)\n\u001b[0;32m    353\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\sparse_tensor.py\u001b[0m in \u001b[0;36m_to_batched_tensor_list\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m    342\u001b[0m       raise ValueError(\n\u001b[0;32m    343\u001b[0m           \"Unbatching a sparse tensor is only supported for rank >= 1\")\n\u001b[1;32m--> 344\u001b[1;33m     return [gen_sparse_ops.serialize_many_sparse(\n\u001b[0m\u001b[0;32m    345\u001b[0m         \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdense_shape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    346\u001b[0m         out_type=dtypes.variant)]\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_sparse_ops.py\u001b[0m in \u001b[0;36mserialize_many_sparse\u001b[1;34m(sparse_indices, sparse_values, sparse_shape, out_type, name)\u001b[0m\n\u001b[0;32m    495\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    496\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 497\u001b[1;33m       \u001b[0m_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    498\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    499\u001b[0m       \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   6841\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\" name: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6842\u001b[0m   \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6843\u001b[1;33m   \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6844\u001b[0m   \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6845\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: indices[2] = [0,23236] is out of order. Many sparse ops require sorted indices.\n    Use `tf.sparse.reorder` to create a correctly ordered copy.\n\n [Op:SerializeManySparse]"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# fit the keras model on the dataset\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "d288edb4-d778-4031-97bc-062ebeaec326",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import sparse\n",
    "from tensorflow import SparseTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "1da48f40-c11a-46d1-8f30-000adff3c1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/40896157/scipy-sparse-csr-matrix-to-tensorflow-sparsetensor-mini-batch-gradient-descent\n",
    "def convert_sparse_matrix_to_sparse_tensor(X):\n",
    "    coo = X.tocoo()\n",
    "    indices = np.mat([coo.row, coo.col]).transpose()\n",
    "    return tf.SparseTensor(indices, coo.data, coo.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "517429f3-c9d1-464c-92de-af29cdfbc291",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.framework.sparse_tensor.SparseTensor at 0x21202313640>"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_sparse_matrix_to_sparse_tensor(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "66c536ec-0053-48a2-8226-bc0fb405beee",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X_tf = convert_sparse_matrix_to_sparse_tensor(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "436f3180-2325-4d45-8d45-01c231e63456",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.framework.sparse_tensor.SparseTensor at 0x21205810e50>"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "55593db0-ffa9-4ae4-898b-dd1588f40d1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.framework.sparse_tensor.SparseTensor at 0x21205810ca0>"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse.reorder(test_X_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "81304b04-deac-440d-8d82-ff47e97ae348",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X_tf_reordered = sparse.reorder(test_X_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "437246e9-f78f-41aa-a4cf-626a97092da4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.framework.sparse_tensor.SparseTensor at 0x212058101c0>"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X_tf_reordered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "79f77ae7-3338-4356-92b3-8efa611d9ea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([75000, 44297])"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X_tf_reordered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "bebf9c1c-a7bd-4d95-a237-3e03879673a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X_train_tf = convert_sparse_matrix_to_sparse_tensor(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "91c0c383-ba3e-4871-8c59-accf7600e10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X_train_tf_reordered = sparse.reorder(test_X_train_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c19ce66-2e35-46c9-8679-c8452523c744",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bb06add2-0617-4724-b37c-2fa38a790885",
   "metadata": {},
   "outputs": [],
   "source": [
    "from win32com.client import Dispatch\n",
    "speak = Dispatch(\"SAPI.SpVoice\").Speak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "38b37dde-3e34-4d7b-aca2-1f2c2fdc062c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speak(\"modeling complete\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
