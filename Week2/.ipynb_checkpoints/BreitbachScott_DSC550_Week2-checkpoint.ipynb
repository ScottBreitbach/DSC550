{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scott Breitbach\n",
    "## 20-March-2021\n",
    "## DSC550, Week 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import unicodedata\n",
    "import sys\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk import pos_tag\n",
    "from nltk import word_tokenize\n",
    "import nltk\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Read the *controversial-comments.jsonl* file and pre-process the text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>con</th>\n",
       "      <th>txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Well it's great that he did something about th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>You are right Mr. President.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>You have given no input apart from saying I am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>I get the frustration but the reason they want...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>I am far from an expert on TPP and I would ten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949995</th>\n",
       "      <td>0</td>\n",
       "      <td>I genuinely can't understand how anyone can su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949996</th>\n",
       "      <td>0</td>\n",
       "      <td>As a reminder, this subreddit [is for civil di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949997</th>\n",
       "      <td>0</td>\n",
       "      <td>K. Don't explain why or anything.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949998</th>\n",
       "      <td>0</td>\n",
       "      <td>[deleted]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949999</th>\n",
       "      <td>0</td>\n",
       "      <td>Ya, sociopaths are known for celebrating their...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>950000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        con                                                txt\n",
       "0         0  Well it's great that he did something about th...\n",
       "1         0                       You are right Mr. President.\n",
       "2         0  You have given no input apart from saying I am...\n",
       "3         0  I get the frustration but the reason they want...\n",
       "4         0  I am far from an expert on TPP and I would ten...\n",
       "...     ...                                                ...\n",
       "949995    0  I genuinely can't understand how anyone can su...\n",
       "949996    0  As a reminder, this subreddit [is for civil di...\n",
       "949997    0                  K. Don't explain why or anything.\n",
       "949998    0                                          [deleted]\n",
       "949999    0  Ya, sociopaths are known for celebrating their...\n",
       "\n",
       "[950000 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allCommentsDF = pd.read_json(\"controversial-comments\\controversial-comments.jsonl\", lines=True)\n",
    "allCommentsDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grab a sample of the set to work with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "commentsDF = allCommentsDF.sample(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A) Convert all text to lowercase letters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "commentsDF.txt = commentsDF['txt'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>con</th>\n",
       "      <th>txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>202617</th>\n",
       "      <td>0</td>\n",
       "      <td>meh.  i'm sure there will be a leaked email so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812710</th>\n",
       "      <td>0</td>\n",
       "      <td>politicians should take note, that if you're g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124885</th>\n",
       "      <td>0</td>\n",
       "      <td>he's really got it in for aaron rodgers' ankle.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545351</th>\n",
       "      <td>0</td>\n",
       "      <td>of course not. he's just trying to trick you i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751713</th>\n",
       "      <td>0</td>\n",
       "      <td>oops sorry wrong comment.\\n\\nbasically i said ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        con                                                txt\n",
       "202617    0  meh.  i'm sure there will be a leaked email so...\n",
       "812710    0  politicians should take note, that if you're g...\n",
       "124885    0    he's really got it in for aaron rodgers' ankle.\n",
       "545351    0  of course not. he's just trying to trick you i...\n",
       "751713    0  oops sorry wrong comment.\\n\\nbasically i said ..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "commentsDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B) Remove all punctuation from the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation = dict.fromkeys(i for i in range(sys.maxunicode) \n",
    "                            if unicodedata.category(chr(i)).startswith('P'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "commentsDF.txt = [string.translate(punctuation) for string in commentsDF.txt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>con</th>\n",
       "      <th>txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>202617</th>\n",
       "      <td>0</td>\n",
       "      <td>meh  im sure there will be a leaked email soon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812710</th>\n",
       "      <td>0</td>\n",
       "      <td>politicians should take note that if youre goo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124885</th>\n",
       "      <td>0</td>\n",
       "      <td>hes really got it in for aaron rodgers ankle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545351</th>\n",
       "      <td>0</td>\n",
       "      <td>of course not hes just trying to trick you int...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751713</th>\n",
       "      <td>0</td>\n",
       "      <td>oops sorry wrong comment\\n\\nbasically i said t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        con                                                txt\n",
       "202617    0  meh  im sure there will be a leaked email soon...\n",
       "812710    0  politicians should take note that if youre goo...\n",
       "124885    0       hes really got it in for aaron rodgers ankle\n",
       "545351    0  of course not hes just trying to trick you int...\n",
       "751713    0  oops sorry wrong comment\\n\\nbasically i said t..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "commentsDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C) Remove stop words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "\n",
    "def removeStopWords(string):\n",
    "    tokenized_words = word_tokenize(string)\n",
    "    return [word for word in tokenized_words if word not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "commentsDF.txt = commentsDF.txt.apply(lambda x: removeStopWords(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>con</th>\n",
       "      <th>txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>202617</th>\n",
       "      <td>0</td>\n",
       "      <td>[meh, im, sure, leaked, email, soon, dnc, staf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812710</th>\n",
       "      <td>0</td>\n",
       "      <td>[politicians, take, note, youre, good, avoid, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124885</th>\n",
       "      <td>0</td>\n",
       "      <td>[hes, really, got, aaron, rodgers, ankle]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545351</th>\n",
       "      <td>0</td>\n",
       "      <td>[course, hes, trying, trick, believing, lies, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751713</th>\n",
       "      <td>0</td>\n",
       "      <td>[oops, sorry, wrong, comment, basically, said,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        con                                                txt\n",
       "202617    0  [meh, im, sure, leaked, email, soon, dnc, staf...\n",
       "812710    0  [politicians, take, note, youre, good, avoid, ...\n",
       "124885    0          [hes, really, got, aaron, rodgers, ankle]\n",
       "545351    0  [course, hes, trying, trick, believing, lies, ...\n",
       "751713    0  [oops, sorry, wrong, comment, basically, said,..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "commentsDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D) Apply NLTK's PorterStemmer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "porter = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "commentsDF.txt = commentsDF.txt.apply(lambda x: [porter.stem(word) for word in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>con</th>\n",
       "      <th>txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>202617</th>\n",
       "      <td>0</td>\n",
       "      <td>[meh, im, sure, leak, email, soon, dnc, staffe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812710</th>\n",
       "      <td>0</td>\n",
       "      <td>[politician, take, note, your, good, avoid, sc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124885</th>\n",
       "      <td>0</td>\n",
       "      <td>[he, realli, got, aaron, rodger, ankl]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545351</th>\n",
       "      <td>0</td>\n",
       "      <td>[cours, he, tri, trick, believ, lie, msm, liza...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751713</th>\n",
       "      <td>0</td>\n",
       "      <td>[oop, sorri, wrong, comment, basic, said, coun...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        con                                                txt\n",
       "202617    0  [meh, im, sure, leak, email, soon, dnc, staffe...\n",
       "812710    0  [politician, take, note, your, good, avoid, sc...\n",
       "124885    0             [he, realli, got, aaron, rodger, ankl]\n",
       "545351    0  [cours, he, tri, trick, believ, lie, msm, liza...\n",
       "751713    0  [oop, sorri, wrong, comment, basic, said, coun..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "commentsDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Get text into a usable form for model-building."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A) Convert each text entry into a word-count vector.\n",
    "See sections 5.3 & 6.8 in the *Machine Learning with Python Cookbook*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# commentsDF['WCV'] = commentsDF.txt.apply(lambda x: count.fit_transform(x).toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting to word-count vector threw an error when the 'txt' field contained an empty list. This function should return an empty list when coming across this error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def wordCountVector(wordList):\n",
    "#     try:\n",
    "#         array = count.fit_transform(wordList).toarray()\n",
    "#         return array\n",
    "#     except:\n",
    "#         return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# commentsDF['WCV'] = commentsDF.txt.apply(lambda x: wordCountVector(x))\n",
    "# commentsDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apparently this needs to be in one large matrix so let's try it again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all the text data into a list of strings, \n",
    "# with each tweet as one string in the list\n",
    "\n",
    "text_data, string = [], \" \"\n",
    "\n",
    "for text in commentsDF.txt:\n",
    "    text_data.append(string.join(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Word-count vector as a DataFrame\n",
    "# wordCountVector = pd.DataFrame(count.fit_transform(text_data).toarray(), columns=count.get_feature_names())\n",
    "# wordCountVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<100x1004 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 1661 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Word-count vector as a sparse matrix\n",
    "sparseWCV = count.fit_transform(text_data)\n",
    "sparseWCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B) Convert each text entry into a part-of-speech tag vector.\n",
    "See section 6.7 in the *Machine Learning with Python Cookbook*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('meh', 'NN'), ('im', 'JJ'), ('sure', 'JJ'), ('leak', 'JJ'), ('email', 'NN')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag(commentsDF.txt.iloc[0])[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>con</th>\n",
       "      <th>txt</th>\n",
       "      <th>PoS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>202617</th>\n",
       "      <td>0</td>\n",
       "      <td>[meh, im, sure, leak, email, soon, dnc, staffe...</td>\n",
       "      <td>[NN, JJ, JJ, JJ, NN, RB, JJ, NN, NN, JJS, NN, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812710</th>\n",
       "      <td>0</td>\n",
       "      <td>[politician, take, note, your, good, avoid, sc...</td>\n",
       "      <td>[JJ, VB, VB, PRP$, JJ, NN, NN, NN, VBP, CD, RB...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        con                                                txt  \\\n",
       "202617    0  [meh, im, sure, leak, email, soon, dnc, staffe...   \n",
       "812710    0  [politician, take, note, your, good, avoid, sc...   \n",
       "\n",
       "                                                      PoS  \n",
       "202617  [NN, JJ, JJ, JJ, NN, RB, JJ, NN, NN, JJS, NN, ...  \n",
       "812710  [JJ, VB, VB, PRP$, JJ, NN, NN, NN, VBP, CD, RB...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "commentsDF['PoS'] = commentsDF.txt.apply(lambda x: [tag for word, tag in nltk.pos_tag(x)])\n",
    "commentsDF.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This also needs to be in a matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "oneHotMulti = MultiLabelBinarizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "taggedTweets = []\n",
    "\n",
    "for tweet in text_data:\n",
    "    tweetTag = nltk.pos_tag(word_tokenize(tweet))\n",
    "    taggedTweets.append([tag for word, tag in tweetTag])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Part-of-speech tags as a DataFrame\n",
    "# partOfSpeech = pd.DataFrame(oneHotMulti.fit_transform(taggedTweets), columns=oneHotMulti.classes_)\n",
    "# partOfSpeech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 1, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 1, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 1, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Part-of-speech tags as a coded matrix\n",
    "posMatrix = oneHotMulti.fit_transform(taggedTweets)\n",
    "posMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 29)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posMatrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C) Convert each entry into a term frequency-inverse document frequency (**tfidf**) vector.\n",
    "See section 6.9 in the *Machine Learning with Python Cookbook*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # tfidf vector as a Dataframe:\n",
    "# tfidfVector = pd.DataFrame(tfidf.fit_transform(text_data).toarray(), columns=tfidf.get_feature_names())\n",
    "# tfidfVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<100x1004 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1661 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tfidf vector as a sparse matrix:\n",
    "sparseTfidf = tfidf.fit_transform(text_data)\n",
    "sparseTfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Follow-Up Question**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For the three techniques in problem 2 above, give an example where each would be useful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A) Word-count vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the article [Building a Better Profanity Detection Library with scikit-learn](https://victorzhou.com/blog/better-profanity-detection-with-scikit-learn/) the author, Victor Zhou, discusses how he was looking for a pre-built way to detect profanity in some text he was working with. He found a few options, most of which were just checking against a pre-generated list, but they weren't as comprehensive as he'd like. So, he set off to create his own profanity detection library using machine learning.  \n",
    "In order to build his model, he used a couple of datasets that were already labeled by humans as to whether or not they contained offensive or hate speech.  He then created a word-count vector using scikit-learn's CountVectorizer in order to feed his machine learning model and now it is available  to install in python as `profanity-check`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B) Part-of-speech vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part-of-speech vectors are useful when working with and understanding language. Beyond just the written words themselves, they have meaning and the same word can mean different things in different contexts.  \n",
    "An example of the usefulness of POS tagging is in speech-to-text applications. Because the English language contains homonyms (specifically homographs, or words that are spelled the same but mean different things), POS tagging can be used to differentiate which meaning, and therefore which pronunciation is appropriate (e.g. minute (60 seconds) vs minute (very small))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C) TF-IDF vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF (term frequency-inverse document frequency) is a way of weighting words based on two metrics: term frequency, or how much a word shows up in a text, and inverse document frequency, which makes words score lower if they are very common across all documents. The idea being that higher scoring words are more important to that particular text.  \n",
    "While there are a lot of uses for tfidf (from Natural Language Processing to auto-tagging / finding keywords), one of the most common uses is probably in search. Tfidf is used to find rank and return the most relevant results to your query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
